{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from numpy.core.fromnumeric import argmax, argmin\n",
    "from evaluator import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import threading\n",
    "import matplotlib.pyplot as plt\n",
    "from daphne import daphne\n",
    "\n",
    "from primitives import log\n",
    "from plots import plots\n",
    "\n",
    "sys.setrecursionlimit(100000)\n",
    "threading.stack_size(200000000)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_until_observe_or_end(res):\n",
    "    cont, args, sigma = res\n",
    "    res = cont(sigma, *args)\n",
    "    while type(res) is tuple:\n",
    "        if res[2]['type'] == 'observe':\n",
    "            return res\n",
    "        cont, args, sigma = res\n",
    "        res = cont(sigma, *args)\n",
    "\n",
    "    res = (res, None, {'done' : True}) #wrap it back up in a tuple, that has \"done\" in the sigma map\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_particles(particles, log_weights):\n",
    "    L = len(log_weights)\n",
    "    log_ws = torch.FloatTensor(log_weights)\n",
    "    discrete_dist = torch.distributions.categorical.Categorical(logits=log_ws)\n",
    "    new_particles = []\n",
    "    for _ in range(L):\n",
    "        k = discrete_dist.sample()\n",
    "        new_particles.append(particles[k])\n",
    "\n",
    "    logZ = torch.logsumexp(log_ws,0) - torch.log(torch.tensor(log_ws.shape[0],dtype=float))\n",
    "\n",
    "    return logZ, new_particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMC(n_particles, exp):\n",
    "    particles = []\n",
    "    weights = []\n",
    "    logZs = []\n",
    "    sigma = {'logW':0}\n",
    "    output = lambda _, x: x\n",
    "\n",
    "    for i in range(n_particles):\n",
    "        cont, args, sigma = evaluate(exp, sigma, env=None)(sigma, 'addr_start', output)\n",
    "        logW = 0.\n",
    "        weights.append(logW)\n",
    "        res = cont, args, {'logW':weights[i]}\n",
    "        particles.append(res)\n",
    "\n",
    "    done = False\n",
    "    smc_cnter = 0\n",
    "    while not done:\n",
    "        for i in range(n_particles): #Even though this can be parallelized, we run it serially\n",
    "            res = run_until_observe_or_end(particles[i])\n",
    "            if 'done' in res[2]: #this checks if the calculation is done\n",
    "                particles[i] = res[0]\n",
    "                if i == 0:\n",
    "                    done = True  #and enforces everything to be the same as the first particle\n",
    "                    address = ''    \n",
    "                else:\n",
    "                    if not done:        # is the /first/ particle i=0 done?\n",
    "                        raise RuntimeError('Failed SMC, finished one calculation before the other')\n",
    "            else:  # res[2] == 'observe'\n",
    "                cont, args, sigma = res\n",
    "                weights[i] = res[2]['logW'].clone().detach()        # get weights\n",
    "                particles[i] = cont, args, {'logW':weights[i]}      # get continuation\n",
    "\n",
    "                if i == 0:\n",
    "                    address = sigma['alpha']\n",
    "                try:\n",
    "                    assert(sigma['alpha'] == address)\n",
    "                except:\n",
    "                    raise AssertionError('particle address error')\n",
    "\n",
    "        if not done:\n",
    "            logZn, particles = resample_particles(particles, weights)\n",
    "            logZs.append(logZn)\n",
    "            \n",
    "        smc_cnter += 1  # number of continuations/observes completed. \n",
    "\n",
    "    if logZs == []:\n",
    "        return 0, particles\n",
    "    else:\n",
    "        return logZs[-1], particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# exp = daphne(['desugar-hoppl-cps', '-i', 'C:/Users/jlovr/CS532-project/Probabilistic-Programming/Project/smc/programs/{}.daphne'.format(7)])\n",
    "# with open('C:/Users/jlovr/CS532-project/Probabilistic-Programming/Project/smc/programs/{}.daphne'.format(7),'w') as f:\n",
    "#     json.dump(exp, f)\n",
    "\n",
    "with open('C:/Users/jlovr/CS532-project/Probabilistic-Programming/Project/smc/programs/{}.daphne'.format(7),'r') as f:\n",
    "    exp = json.load(f)\n",
    "\n",
    "logZ_list = []\n",
    "\n",
    "for n_particles in [1]:\n",
    "    \n",
    "    logZ, particles = SMC(n_particles, exp)\n",
    "\n",
    "    values = torch.stack(particles)\n",
    "    \n",
    "    #### presentation of the results\n",
    "\n",
    "    print(\"Number of particles:\", n_particles)\n",
    "\n",
    "    print('posterior mean:', values.float().detach().numpy().mean(axis=0))\n",
    "    if n_particles > 1:\n",
    "        print('posterior variance: ', np.diag(np.cov(values.float().detach().numpy(),rowvar=False)))  \n",
    "        \n",
    "    print(\"logZ:\", np.array(logZ, dtype=float))\n",
    "    logZ_list.append(logZ)\n",
    "    \n",
    "    # plots(particles, 7, n_particles)\n",
    "    \n",
    "    # plt.figure(figsize=(8,4))\n",
    "    # plt.xlabel(\"$\\log_{10} (n)$\")\n",
    "    # plt.ylabel(\"logZ\")\n",
    "    # plt.title(\"Marginal log-probability estimate returned by SMC for program \" + str(7))\n",
    "\n",
    "    # plt.plot(logZ_list)\n",
    "    # figstr = \"logZ_estimates/program_\"+str(7)\n",
    "    # plt.savefig(figstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logZ)\n",
    "print(values)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ac34c6cd7eeed34b8ef5a26d96fb33c83d96247b1e5d7492eca8d43f8ea1173"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
